# NYU Digital Forensics CS-GY 6963
## Assignment 6: Python Script
## Author: Casey McGinley <cmm771@nyu.edu>

This script was created for NYU's CS-GY 6963 Digital Forensics class taught by Prof. Marc Budofsky. This script utilizes various Python modules useful in the manipulation of disk images, as well as using subprocess to make calls to other useful tools like Sleuthkit.

### Use
This script is called from a unix command line as follows:
```
usage: extract.py [-h] (-i IMAGES [IMAGES ...] | -l IMAGE_LIST) [-f]

Extracting Images and PDFs

optional arguments:
  -h, --help            show this help message and exit
  -i IMAGES [IMAGES ...], --image IMAGES [IMAGES ...]
                        Filename(s)/path(s) to the disk image(s) to be
                        processed
  -l IMAGE_LIST, --image_list IMAGE_LIST
                        Filename/path of text file containing new-line
                        separated paths for each image file to be processed
  -f, --force           Flag determining if existing extraction directories
                        should be overwritten
                        
```
A DB called *carved_files.db* is created, as well as a directory called *extract*, containing all the image and PDF files found. Additionally a human-readable text file called *extraction_report.txt* is generated.

Also, a temporary directory called *tmp_extract* is also generated by TSK, but should be removed by the script upon completion. If you find the directory is still there, then likely the last run had some Exception.

### Shortcomings
This script does still have some shortcoming which could be improved with some additional tinkering. These include:
  - Suppressing superflous warnings from PIL
  - Finding the cause as to why pyPdf hangs on some files; this led to me having to change my strategy with detecting PDFs; instead of just checking for an error with pyPdf, I had to make sure it had a PDF extension first, as one of the log files from the disk images would cause pyPdf to hang idefinitely when opened
  - Expanding on metadata columns for significant fields, instead of dumping it as a blob; ultimately I went with the blob though because the variety of metadata fields between files was too great
  - Determining file types might be enhanced with more comprehensive list of image extensions, or possibly by checking magic numbers instead
